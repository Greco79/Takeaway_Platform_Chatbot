import requests
from langchain.schema import HumanMessage, AIMessage
from emotion_classify import emotion_analyze
from faq_vector_preorder import query_preorder_faq

# ç¡…åŸºæµåŠ¨ Qwen3 æ¨¡åž‹ API é…ç½®
API_URL = "https://api.siliconflow.cn/v1/chat/completions"
API_KEY = ""  
MODEL_NAME = "Qwen/QwQ-32B"

# å¤šè½®å¯¹è¯åŽ†å²
history_messages = []

# é¤å‰/é¤åŽåˆ†ç±»å™¨
from transformers import pipeline
order_stage_classifier = pipeline("text-classification", model="./bert_classify_output/checkpoint-75", tokenizer="./bert_classify_output/checkpoint-75")

# æž„é€ åŽ†å²ä¸Šä¸‹æ–‡ Prompt
def build_history_text(messages, max_rounds=2):
    history = messages[-max_rounds * 2:] if len(messages) >= max_rounds * 2 else messages
    lines = []
    i = 0
    while i < len(history) - 1:
        if isinstance(history[i], HumanMessage) and isinstance(history[i+1], AIMessage):
            user_msg = history[i].content
            ai_msg = history[i+1].content
            lines.append(f"ç”¨æˆ·ï¼š{user_msg}\nå®¢æœï¼š{ai_msg}")
            i += 2
        else:
            i += 1
    return "\n".join(lines)

# è¯„è®ºæ–¹é¢æŠ½å–
def get_aspects(text):
    aspect_map = {
        "é…é€é€Ÿåº¦": ["é€è´§", "è¿Ÿåˆ°", "æ…¢", "å¿«", "å‡†æ—¶", "åŠæ—¶", "é£žå¿«", "é€Ÿåº¦", "è¿…é€Ÿ", "æå‰", "è¶…æ—¶"],
        "éª‘æ‰‹æ€åº¦": ["æ€åº¦", "äººå¾ˆå¥½", "æœ‰ç¤¼è²Œ", "æé†’", "è¯­æ°”", "æŒ‚ç”µè¯", "æœåŠ¡", "çˆ¬æ¥¼æ¢¯"],
        "å•†å®¶æ€åº¦": ["è€æ¿", "åº—å®¶"],
        "åŒ…è£…æƒ…å†µ": ["åŒ…è£…", "æ¼", "æ´’", "å¯†å°", "æ•´æ´", "å«ç”Ÿ", "ç›’å­ç ´"],
        "èœå“å‘³é“": ["å‘³é“", "éš¾åƒ", "å¥½åƒ", "å£å‘³", "ä¸æ–°é²œ", "é¦™", "è¾£", "æ·¡", "å’¸", "æ²¹", "è…»"],
        "åˆ†é‡æ€§ä»·æ¯”": ["é‡", "å®žåœ¨", "æ€§ä»·æ¯”", "åƒä¸é¥±"],
        "è®¢å•é—®é¢˜": ["å‘ç¥¨", "å¤‡æ³¨", "é¤å…·", "æ¼é€"],
        "é¤å“å‡†ç¡®æ€§": ["é€é”™", "ç‚¹é”™", "ä¸æ˜¯æˆ‘ç‚¹çš„"],
        "é…é€æ–¹å¼": ["é€ä¸Šæ¥¼", "ä¸‹æ¥¼æ‹¿"],
        "å•†å®¶æŽ¥å•æƒ…å†µ": ["æ‹’å•", "å–æ¶ˆ", "æŽ¥å•"],
        "å¹³å°": ["ä¼˜æƒ "]
    }
    matched = []
    for aspect, keywords in aspect_map.items():
        if any(k in text for k in keywords):
            matched.append(aspect)
    return matched or ["å…¶ä»–"]

# åˆ¤æ–­æ˜¯å¦é¤å‰
def is_preorder_query(text):
    result = order_stage_classifier(text)[0]
    print(f"[é˜¶æ®µåˆ¤æ–­] label: {result['label']} | score: {round(result['score'], 4)} | æ–‡æœ¬: {text}")
    return result["label"] == "LABEL_0"

# è½¬äººå·¥å…³é”®è¯
def need_manual_intervention(text, emotion):
    bad_keywords = ["å·®è¯„", "æŠ•è¯‰", "å†ä¹Ÿä¸", "æ¶å¿ƒ", "ä¸€æ¬¡æœ€å·®", "æƒ³é€€æ¬¾"]
    return emotion == "æ¶ˆæž" and any(k in text for k in bad_keywords)

# æž„é€  Prompt
def generate_prompt(comment, aspects, emotion, history=None):
    aspect_str = "ã€".join(aspects)
    tone = "äº²åˆ‡ã€çœŸè¯šã€æ¸©å’Œ" if emotion == "ç§¯æž" else "è¯šæ³ã€å®‰æŠšã€çœŸè¯š"
    history_text = history + "\n---\n" if history else ""

    return f"""ä½ æ˜¯ä¸€åå¤–å–å¹³å°çš„ä¸“ä¸šå®¢æœï¼Œè¯·ä½ ä»¥{tone}çš„è¯­æ°”ï¼Œç”¨ä¸€å¥è¯å›žå¤ç”¨æˆ·çš„è¯„è®ºï¼Œè¡¨è¾¾ç†è§£ã€æ„Ÿè°¢æˆ–å®‰æŠšã€‚
    è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
    - ä»…è¡¨è¾¾ç†è§£ã€æ„Ÿè°¢æˆ–å®‰æŠšï¼›**ä¸å¾—**æ¶‰åŠé€€æ¬¾ã€è°ƒæŸ¥ã€å¤„ç†ã€è½¬å•ç­‰æ“ä½œç±»æ‰¿è¯º
    - **ä»…å›žå¤ä¸€å¥è¯ï¼ŒæŽ§åˆ¶åœ¨ 50 ä¸ªå­—ä»¥å†…**
    - **ç¦æ­¢ç¼–å·ã€åˆ†ç‚¹æˆ–æ¨¡æ¿åŒ–æŽªè¾ž**
    - è¯­è¨€å¿…é¡»è‡ªç„¶ã€æœ‰æ¸©åº¦ï¼Œè´´è¿‘çœŸå®žå®¢æœè¯´è¯é£Žæ ¼ï¼Œé¿å…å¤ªå®˜æ–¹æˆ–ç”Ÿç¡¬

    ã€ç¤ºä¾‹ã€‘
    ç”¨æˆ·è¯„è®ºï¼šä»Šå¤©çš„èœå¾ˆéš¾åƒï¼
    æƒ…ç»ªï¼šæ¶ˆæž
    æ¶‰åŠæ–¹é¢ï¼šèœå“å£å‘³
    å®¢æœå›žå¤ï¼šçœŸçš„å¾ˆæŠ±æ­‰ä»Šå¤©çš„èœæ²¡æœ‰è®©æ‚¨æ»¡æ„ï¼Œæ‚¨çš„åé¦ˆæˆ‘ä»¬ä¸€å®šä¼šè®¤çœŸè®°å½•å¹¶åŠªåŠ›æ”¹è¿›ã€‚

    ---
    {history_text}
    ç”¨æˆ·è¯„è®ºï¼š{comment}
    æƒ…ç»ªï¼š{emotion}
    æ¶‰åŠæ–¹é¢ï¼š{aspect_str}
    è¯·ç”Ÿæˆä¸€å¥å®¢æœå›žå¤ï¼š
    """

# ä¸»å…¥å£å‡½æ•°
def generate_reply(user_input):
    global history_messages

    if is_preorder_query(user_input):
        answer = query_preorder_faq(user_input)
        history_messages.append(HumanMessage(content=user_input))
        history_messages.append(AIMessage(content=answer))
        return answer

    emotion, score = emotion_analyze(user_input)
    print(f"[æƒ…ç»ªåˆ†æž] â†’ {emotion} | ç½®ä¿¡åº¦ï¼š{round(score, 4)}")

    if need_manual_intervention(user_input, emotion) or (emotion == "æ¶ˆæž" and score < 0.6):
        return "å¾ˆæŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œç³»ç»Ÿå·²è®°å½•é—®é¢˜ï¼Œå·²ä¸ºæ‚¨è½¬æŽ¥äººå·¥å®¢æœå¤„ç†ï½ž"

    aspects = get_aspects(user_input)
    history_text = build_history_text(history_messages)
    prompt = generate_prompt(user_input, aspects, emotion, history=history_text)

    # è°ƒç”¨ Qwen3 API
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 128,
        "temperature": 0.1,
        "top_p": 0.85,
        "top_k": 20,
        "frequency_penalty": 0.8,
        "stream": False
    }
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(API_URL, json=payload, headers=headers)
        result = response.json()
        content = result['choices'][0]['message']['content'].strip()
        reply = content.split("ã€‚")[0] + "ã€‚"

        history_messages.append(HumanMessage(content=user_input))
        history_messages.append(AIMessage(content=reply))

        print("ðŸ§¾ åŽŸå§‹è¾“å‡ºï¼š", content)
        print("âœ… æœ€ç»ˆå›žå¤ï¼š", reply)
        return reply
    except Exception as e:
        print("âŒ è°ƒç”¨ Qwen3 API å‡ºé”™ï¼š", e)
        return "ç³»ç»Ÿæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åŽå†è¯•ï½ž"

# ç¤ºä¾‹è¿è¡Œ
if __name__ == "__main__":
    while True:
        comment = input("è¯·è¾“å…¥è¯„è®ºå†…å®¹ï¼ˆè¾“å…¥ q é€€å‡ºï¼‰ï¼š").strip()
        if comment.lower() == "q":
            break
        print(generate_reply(comment))
