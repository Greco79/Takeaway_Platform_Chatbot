# faq_preorder_vector.py
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document


try:
    embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh")
    db = Chroma(persist_directory="./chroma/chroma_faq_preorder_db", embedding_function=embedding_model)
    print("âœ… æˆåŠŸåŠ è½½ Chroma å‘é‡åº“ï¼")
except Exception as e:
    print("âŒ åŠ è½½ Chroma å‘é‡åº“å¤±è´¥ï¼š", e)
    db = None


def query_preorder_faq(query: str):
    print(f"ğŸŸ¡ [Debug] query_preorder_faq è¢«è°ƒç”¨ï¼Œç”¨æˆ·è¾“å…¥ï¼š{query}")
    result = db.similarity_search_with_score(query, k=1)
    print(f"[Debug] åŒ¹é… raw ç»“æœ: {result}")

    if result:
        doc, score = result[0]
        print(f"[Debug] åŒ¹é…åˆ†æ•°: {score:.4f}, åŒ¹é…é—®é¢˜: {doc.page_content}")
        return doc.metadata.get("answer", "æ‚¨å¥½ï¼Œè¿™æ˜¯ç›¸å…³ä¿¡æ¯ï½")

    print(f"[Debug] æ— FAQå‘½ä¸­ï¼Œè¿”å›é»˜è®¤å›å¤")
    return "å¾ˆæŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·è”ç³»äººå·¥å®¢æœå¤„ç†ã€‚"

if __name__ == "__main__":
    print("ğŸ“Œ æ­£åœ¨æµ‹è¯• FAQ æŸ¥è¯¢æ¥å£...")

    # æ‰‹åŠ¨æ„é€ ä¸€ä¸ªæµ‹è¯•é—®é¢˜
    test_query = "å¯ä»¥å¾®ä¿¡æ”¯ä»˜å—"

    # è°ƒç”¨å‡½æ•°
    answer = query_preorder_faq(test_query)

    print(f"âœ… æœ€ç»ˆè¿”å›ç»“æœ: {answer}")



